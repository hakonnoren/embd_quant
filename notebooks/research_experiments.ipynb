{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Experiments: Answering Open Questions\n",
    "\n",
    "Numerical experiments to test hypotheses from `docs/research_questions.md`.\n",
    "\n",
    "## Experiments\n",
    "1. **Distribution Analysis** — Kurtosis, skewness, Gaussianity per dimension\n",
    "2. **Median Offset Prediction** — Does ||m||² predict when median centering helps?\n",
    "3. **Bootstrap Confidence Intervals** — Is Lloyd-Max > float32 significant?\n",
    "4. **Correlation Structure** — PCA vs Matryoshka dimension ordering\n",
    "5. **MSE vs Ranking** — Kendall's tau: does lower MSE always mean better NDCG?\n",
    "6. **Calibration-Free 2-bit** — Fixed boundaries vs Lloyd-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "\n",
    "CACHE = Path('cache/embeddings')\n",
    "\n",
    "MODELS = {\n",
    "    'mxbai': ('mxbai-embed-large-v1', 1024, [1024, 512, 256, 128, 64]),\n",
    "    'nomic': ('nomic-embed-text-v1.5', 768, [768, 512, 256, 128, 64]),\n",
    "    'minilm': ('all-MiniLM-L6-v2', 384, [384]),\n",
    "}\n",
    "\n",
    "DATASETS = ['SciFact', 'NFCorpus']\n",
    "\n",
    "def load_emb(model_name, dataset, split='corpus'):\n",
    "    path = CACHE / f'{model_name}_{dataset}_{split}.npy'\n",
    "    return np.load(path)\n",
    "\n",
    "def truncate_normalize(emb, dim):\n",
    "    t = emb[:, :dim].copy()\n",
    "    norms = np.linalg.norm(t, axis=1, keepdims=True)\n",
    "    return t / np.where(norms == 0, 1.0, norms)\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Per-Dimension Distribution Analysis\n",
    "\n",
    "**Question**: Are embedding dimensions Gaussian? If not, Lloyd-Max constants are suboptimal.\n",
    "\n",
    "We compute per-dimension:\n",
    "- **Kurtosis** (Gaussian = 3.0; >3 = heavy tails, <3 = light tails)\n",
    "- **Skewness** (Gaussian = 0; ≠0 = asymmetric)\n",
    "- **Shapiro-Wilk test** (fraction of dims that reject Gaussian at p<0.05)\n",
    "- **Median offset** |median| (how far from zero-centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_distribution(emb, label='', max_dims_for_shapiro=200):\n",
    "    \"\"\"Compute distribution statistics per dimension.\"\"\"\n",
    "    n, d = emb.shape\n",
    "    \n",
    "    kurtoses = stats.kurtosis(emb, axis=0, fisher=False)  # Fisher=False → Gaussian=3\n",
    "    skewnesses = stats.skew(emb, axis=0)\n",
    "    medians = np.median(emb, axis=0)\n",
    "    stds = np.std(emb, axis=0)\n",
    "    \n",
    "    # Shapiro-Wilk on a sample of dims (expensive)\n",
    "    test_dims = min(d, max_dims_for_shapiro)\n",
    "    dim_indices = np.linspace(0, d-1, test_dims, dtype=int)\n",
    "    n_reject = 0\n",
    "    for j in dim_indices:\n",
    "        # Subsample for Shapiro (max 5000)\n",
    "        sample = emb[np.random.choice(n, min(n, 5000), replace=False), j]\n",
    "        _, p = stats.shapiro(sample)\n",
    "        if p < 0.05:\n",
    "            n_reject += 1\n",
    "    \n",
    "    results = {\n",
    "        'kurtosis_mean': np.mean(kurtoses),\n",
    "        'kurtosis_std': np.std(kurtoses),\n",
    "        'kurtosis_range': (np.min(kurtoses), np.max(kurtoses)),\n",
    "        'skewness_mean': np.mean(np.abs(skewnesses)),\n",
    "        'skewness_std': np.std(skewnesses),\n",
    "        'median_offset_rms': np.sqrt(np.mean(medians**2)),\n",
    "        'median_offset_max': np.max(np.abs(medians)),\n",
    "        'std_mean': np.mean(stds),\n",
    "        'std_cv': np.std(stds) / np.mean(stds),  # coefficient of variation\n",
    "        'shapiro_reject_frac': n_reject / test_dims,\n",
    "        'kurtoses': kurtoses,\n",
    "        'skewnesses': skewnesses,\n",
    "        'medians': medians,\n",
    "        'stds': stds,\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# Run analysis for all models × datasets × Matryoshka dims\n",
    "print(f\"{'Model':<10} {'Dataset':<10} {'Dim':>5} {'Kurt µ':>7} {'Kurt σ':>7} \"\n",
    "      f\"{'|Skew| µ':>8} {'|Med| RMS':>9} {'Std CV':>7} {'Shapiro rej':>11}\")\n",
    "print('─' * 90)\n",
    "\n",
    "all_results = {}\n",
    "for mkey, (mname, full_dim, mat_dims) in MODELS.items():\n",
    "    for ds in DATASETS:\n",
    "        corpus = load_emb(mname, ds, 'corpus')\n",
    "        for dim in mat_dims:\n",
    "            emb = truncate_normalize(corpus, dim)\n",
    "            r = analyze_distribution(emb, f'{mkey}/{ds}/d={dim}')\n",
    "            all_results[(mkey, ds, dim)] = r\n",
    "            print(f\"{mkey:<10} {ds:<10} {dim:>5} {r['kurtosis_mean']:>7.2f} {r['kurtosis_std']:>7.2f} \"\n",
    "                  f\"{r['skewness_mean']:>8.3f} {r['median_offset_rms']:>9.4f} \"\n",
    "                  f\"{r['std_cv']:>7.3f} {r['shapiro_reject_frac']:>10.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize kurtosis distribution per model at full dim\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Per-Dimension Kurtosis Distribution (Gaussian = 3.0)', fontweight='bold')\n",
    "\n",
    "for ax, (mkey, (mname, full_dim, _)) in zip(axes, MODELS.items()):\n",
    "    for ds in DATASETS:\n",
    "        r = all_results.get((mkey, ds, full_dim))\n",
    "        if r:\n",
    "            ax.hist(r['kurtoses'], bins=50, alpha=0.5, label=ds, density=True)\n",
    "    ax.axvline(3.0, color='red', linestyle='--', label='Gaussian (3.0)')\n",
    "    ax.set_title(f'{mkey} (d={full_dim})')\n",
    "    ax.set_xlabel('Kurtosis')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xlim(1, 8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Kurtosis vs dimension index (does it change across Matryoshka ordering?)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "fig.suptitle('Kurtosis vs Dimension Index (Matryoshka ordering)', fontweight='bold')\n",
    "\n",
    "for ax, ds in zip(axes, DATASETS):\n",
    "    for mkey, (mname, full_dim, _) in MODELS.items():\n",
    "        r = all_results.get((mkey, ds, full_dim))\n",
    "        if r:\n",
    "            # Smooth with rolling window\n",
    "            k = r['kurtoses']\n",
    "            window = max(1, len(k) // 50)\n",
    "            smoothed = np.convolve(k, np.ones(window)/window, mode='valid')\n",
    "            ax.plot(smoothed, label=f'{mkey}', alpha=0.8)\n",
    "    ax.axhline(3.0, color='red', linestyle='--', alpha=0.5, label='Gaussian')\n",
    "    ax.set_xlabel('Dimension index')\n",
    "    ax.set_ylabel('Kurtosis (smoothed)')\n",
    "    ax.set_title(ds)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How kurtosis and median offset change with Matryoshka truncation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Distribution Properties vs Matryoshka Truncation', fontweight='bold')\n",
    "\n",
    "for mkey, (mname, full_dim, mat_dims) in MODELS.items():\n",
    "    if len(mat_dims) <= 1:\n",
    "        continue\n",
    "    for ds in DATASETS:\n",
    "        kurt_means = [all_results[(mkey, ds, d)]['kurtosis_mean'] for d in mat_dims]\n",
    "        med_rms = [all_results[(mkey, ds, d)]['median_offset_rms'] for d in mat_dims]\n",
    "        std_cv = [all_results[(mkey, ds, d)]['std_cv'] for d in mat_dims]\n",
    "        \n",
    "        axes[0].plot(mat_dims, kurt_means, 'o-', label=f'{mkey}/{ds}', markersize=4)\n",
    "        axes[1].plot(mat_dims, med_rms, 'o-', label=f'{mkey}/{ds}', markersize=4)\n",
    "        axes[2].plot(mat_dims, std_cv, 'o-', label=f'{mkey}/{ds}', markersize=4)\n",
    "\n",
    "axes[0].axhline(3.0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].set_ylabel('Mean Kurtosis'); axes[0].set_title('Kurtosis')\n",
    "axes[1].set_ylabel('RMS Median Offset'); axes[1].set_title('Median Offset')\n",
    "axes[2].set_ylabel('Std CV (σ variation)'); axes[2].set_title('Std Variation')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Matryoshka dim')\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 2: Median Offset Predicts Centering Benefit\n",
    "\n",
    "**Hypothesis**: The NDCG improvement from `binary_median_asym` over `binary_asym` is predicted by the RMS median offset ||m||²/d of the embedding distribution.\n",
    "\n",
    "We compute both quantities for each model × dataset × dim and check the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results that have both binary_asym and binary_median_asym\n",
    "result_files = [\n",
    "    'results/minilm+mxbai+nomic_scif_rot-had/results.json',\n",
    "    'results/minilm+mxbai+nomic_nfco_rot-had/results.json',\n",
    "]\n",
    "\n",
    "all_exp_results = []\n",
    "for rf in result_files:\n",
    "    p = Path(rf)\n",
    "    if p.exists():\n",
    "        with open(p) as f:\n",
    "            data = json.load(f)\n",
    "            all_exp_results.extend(data.get('results', data))\n",
    "\n",
    "# Build lookup: (model, dataset, quant, dim, rotation) -> ndcg@10\n",
    "ndcg_lookup = {}\n",
    "for r in all_exp_results:\n",
    "    key = (r['model'], r['dataset'], r['quantization'], r['matryoshka_dim'], r.get('rotation', 'none'))\n",
    "    ndcg_lookup[key] = r['metrics'].get('ndcg@10', 0)\n",
    "\n",
    "# Compute centering benefit vs median offset\n",
    "MODEL_MAP = {\n",
    "    'mxbai-embed-large-v1': ('mxbai', 'mxbai-embed-large-v1'),\n",
    "    'nomic-embed-text-v1.5': ('nomic', 'nomic-embed-text-v1.5'),\n",
    "    'all-MiniLM-L6-v2': ('minilm', 'all-MiniLM-L6-v2'),\n",
    "}\n",
    "DS_MAP = {'scifact': 'SciFact', 'nfcorpus': 'NFCorpus'}\n",
    "\n",
    "points = []  # (median_offset_rms, ndcg_improvement, label)\n",
    "\n",
    "for model_key, (mkey, mname) in MODEL_MAP.items():\n",
    "    for ds_key, ds_name in DS_MAP.items():\n",
    "        _, _, mat_dims = MODELS[mkey]\n",
    "        for dim in mat_dims:\n",
    "            # Get NDCG for both methods (rotation=none)\n",
    "            ndcg_asym = ndcg_lookup.get((model_key, ds_key, 'binary_asym', dim, 'none'))\n",
    "            ndcg_med = ndcg_lookup.get((model_key, ds_key, 'binary_median_asym', dim, 'none'))\n",
    "            \n",
    "            if ndcg_asym is not None and ndcg_med is not None:\n",
    "                # Get median offset from distribution analysis\n",
    "                dist_key = (mkey, ds_name, dim)\n",
    "                if dist_key in all_results:\n",
    "                    med_rms = all_results[dist_key]['median_offset_rms']\n",
    "                    improvement = ndcg_med - ndcg_asym\n",
    "                    points.append((med_rms, improvement, f'{mkey}/{ds_key}/d={dim}'))\n",
    "\n",
    "if points:\n",
    "    x = np.array([p[0] for p in points])\n",
    "    y = np.array([p[1] for p in points])\n",
    "    labels = [p[2] for p in points]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.scatter(x, y, s=60, alpha=0.7)\n",
    "    \n",
    "    for xi, yi, label in zip(x, y, labels):\n",
    "        ax.annotate(label, (xi, yi), fontsize=6, textcoords='offset points',\n",
    "                   xytext=(5, 3), alpha=0.7)\n",
    "    \n",
    "    # Fit linear regression\n",
    "    if len(x) > 2:\n",
    "        slope, intercept, r_value, p_value, _ = stats.linregress(x, y)\n",
    "        x_fit = np.linspace(x.min(), x.max(), 100)\n",
    "        ax.plot(x_fit, slope * x_fit + intercept, 'r--', alpha=0.5,\n",
    "               label=f'R² = {r_value**2:.3f}, p = {p_value:.4f}')\n",
    "    \n",
    "    ax.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.set_xlabel('RMS Median Offset ||m||/√d')\n",
    "    ax.set_ylabel('NDCG@10 improvement (median_asym − asym)')\n",
    "    ax.set_title('Does Median Offset Predict Centering Benefit?')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\nCorrelation: R² = {r_value**2:.3f}, p-value = {p_value:.4f}')\n",
    "    print(f'Interpretation: {\"Strong\" if r_value**2 > 0.5 else \"Weak\"} predictor')\n",
    "else:\n",
    "    print('No matching data points found — check result file paths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 3: Bootstrap Confidence Intervals\n",
    "\n",
    "**Question**: Is Lloyd-Max > float32 statistically significant, or noise?\n",
    "\n",
    "Resample queries with replacement 2000 times, compute NDCG@10 each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MTEBDataLoader\n",
    "from metrics import RetrievalMetrics\n",
    "\n",
    "data_loader = MTEBDataLoader(Path('cache/datasets'))\n",
    "\n",
    "# Helper functions from hypothesis_tests\n",
    "def search_topk(scores, k):\n",
    "    k = min(k, scores.shape[1])\n",
    "    indices = np.argpartition(-scores, k, axis=1)[:, :k]\n",
    "    for i in range(len(indices)):\n",
    "        idx = indices[i]\n",
    "        indices[i] = idx[np.argsort(-scores[i, idx])]\n",
    "    return indices\n",
    "\n",
    "def packbits(emb):\n",
    "    return np.packbits((emb > 0).astype(np.uint8), axis=1)\n",
    "\n",
    "def unpack_pm1(binary, dim):\n",
    "    unpacked = np.unpackbits(binary, axis=1)[:, :dim].astype(np.float32)\n",
    "    return 2.0 * unpacked - 1.0\n",
    "\n",
    "LLOYD_BOUNDS = np.array([-0.9816, 0.0, 0.9816])\n",
    "LLOYD_LEVELS = np.array([-1.5104, -0.4528, 0.4528, 1.5104], dtype=np.float32)\n",
    "\n",
    "def get_scores_float32(q, c):\n",
    "    return q @ c.T\n",
    "\n",
    "def get_scores_lloyd_max(q, c):\n",
    "    medians = np.median(c, axis=0)\n",
    "    stds = np.std(c, axis=0).clip(1e-10)\n",
    "    z = (c - medians) / stds\n",
    "    codes = np.digitize(z, LLOYD_BOUNDS)\n",
    "    recon_z = LLOYD_LEVELS[codes]\n",
    "    q_scaled = q * stds\n",
    "    return q_scaled @ recon_z.T\n",
    "\n",
    "def get_scores_binary_asym(q, c):\n",
    "    binary = packbits(c)\n",
    "    unpacked = unpack_pm1(binary, c.shape[1])\n",
    "    return q @ unpacked.T\n",
    "\n",
    "def get_scores_binary_median_asym(q, c):\n",
    "    medians = np.median(c, axis=0)\n",
    "    binary = packbits(c - medians)\n",
    "    unpacked = unpack_pm1(binary, c.shape[1])\n",
    "    return (q - medians) @ unpacked.T\n",
    "\n",
    "def get_scores_int8_asym(q, c):\n",
    "    from sentence_transformers.quantization import quantize_embeddings\n",
    "    c_int8 = quantize_embeddings(c, precision='int8')\n",
    "    return q @ c_int8.astype(np.float32).T\n",
    "\n",
    "def get_scores_quaternary_asym(q, c):\n",
    "    boundaries = np.percentile(c, [25, 50, 75], axis=0).astype(np.float32)\n",
    "    codes = np.zeros_like(c, dtype=np.uint8)\n",
    "    codes[c >= boundaries[0]] = 1\n",
    "    codes[c >= boundaries[1]] = 2\n",
    "    codes[c >= boundaries[2]] = 3\n",
    "    dim = c.shape[1]\n",
    "    centroids = np.zeros((4, dim), dtype=np.float32)\n",
    "    for cv in range(4):\n",
    "        mask = (codes == cv)\n",
    "        for j in range(dim):\n",
    "            col_mask = mask[:, j]\n",
    "            if col_mask.any():\n",
    "                centroids[cv, j] = c[col_mask, j].mean()\n",
    "    reconstructed = centroids[codes, np.arange(dim)]\n",
    "    return q @ reconstructed.T\n",
    "\n",
    "METHODS = {\n",
    "    'float32': get_scores_float32,\n",
    "    'lloyd_max_gauss': get_scores_lloyd_max,\n",
    "    'int8_asym': get_scores_int8_asym,\n",
    "    'quaternary_asym': get_scores_quaternary_asym,\n",
    "    'binary_median_asym': get_scores_binary_median_asym,\n",
    "    'binary_asym': get_scores_binary_asym,\n",
    "}\n",
    "\n",
    "print('Methods loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ndcg(query_emb, corpus_emb, qrels, doc_id_to_idx, query_ids,\n",
    "                    methods, n_bootstrap=2000, k=10, seed=42):\n",
    "    \"\"\"\n",
    "    Bootstrap NDCG@k: resample queries with replacement.\n",
    "    Returns dict of method -> array of bootstrapped NDCG values.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_queries = len(query_ids)\n",
    "    \n",
    "    # Pre-compute per-query NDCG for each method\n",
    "    per_query_ndcg = {}  # method -> (n_queries,) array\n",
    "    \n",
    "    for method_name, score_fn in methods.items():\n",
    "        scores = score_fn(query_emb, corpus_emb)\n",
    "        indices = search_topk(scores, 100)\n",
    "        \n",
    "        # Compute per-query NDCG\n",
    "        qrels_idx = {}\n",
    "        for qid in query_ids:\n",
    "            if qid in qrels:\n",
    "                qrels_idx[qid] = {\n",
    "                    doc_id_to_idx[did]: rel\n",
    "                    for did, rel in qrels[qid].items()\n",
    "                    if did in doc_id_to_idx\n",
    "                }\n",
    "        \n",
    "        query_ndcgs = []\n",
    "        for i, qid in enumerate(query_ids):\n",
    "            if qid not in qrels_idx or len(qrels_idx[qid]) == 0:\n",
    "                query_ndcgs.append(np.nan)\n",
    "                continue\n",
    "            retrieved = indices[i, :k]\n",
    "            rels = np.array([qrels_idx[qid].get(int(did), 0) for did in retrieved])\n",
    "            if rels.sum() == 0:\n",
    "                query_ndcgs.append(0.0)\n",
    "                continue\n",
    "            dcg = np.sum(rels / np.log2(np.arange(1, k+1) + 1))\n",
    "            ideal_rels = sorted(qrels_idx[qid].values(), reverse=True)[:k]\n",
    "            ideal_rels = np.array(ideal_rels + [0] * (k - len(ideal_rels)))\n",
    "            idcg = np.sum(ideal_rels / np.log2(np.arange(1, k+1) + 1))\n",
    "            query_ndcgs.append(dcg / idcg if idcg > 0 else 0.0)\n",
    "        \n",
    "        per_query_ndcg[method_name] = np.array(query_ndcgs)\n",
    "        mean_ndcg = np.nanmean(per_query_ndcg[method_name])\n",
    "        print(f'  {method_name:<25s} NDCG@{k} = {mean_ndcg:.4f}')\n",
    "    \n",
    "    # Bootstrap\n",
    "    valid_mask = ~np.isnan(per_query_ndcg['float32'])\n",
    "    valid_indices = np.where(valid_mask)[0]\n",
    "    n_valid = len(valid_indices)\n",
    "    \n",
    "    bootstrap_results = {m: np.zeros(n_bootstrap) for m in methods}\n",
    "    for b in range(n_bootstrap):\n",
    "        sample = rng.choice(valid_indices, size=n_valid, replace=True)\n",
    "        for m in methods:\n",
    "            bootstrap_results[m][b] = np.mean(per_query_ndcg[m][sample])\n",
    "    \n",
    "    return bootstrap_results, per_query_ndcg\n",
    "\n",
    "print('Bootstrap function ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bootstrap for mxbai on SciFact (where Lloyd-Max > float32)\n",
    "model_name = 'mxbai-embed-large-v1'\n",
    "dataset = 'SciFact'\n",
    "ds_key = 'scifact'\n",
    "\n",
    "corpus_emb = load_emb(model_name, dataset, 'corpus')\n",
    "query_emb = load_emb(model_name, dataset, 'queries')\n",
    "corpus_data, queries_data, qrels = data_loader.load_dataset(ds_key)\n",
    "doc_ids, _, query_ids, _ = data_loader.get_texts_for_embedding(corpus_data, queries_data)\n",
    "doc_id_to_idx = {did: i for i, did in enumerate(doc_ids)}\n",
    "\n",
    "print(f'\\n=== {model_name} / {dataset} (full dim={corpus_emb.shape[1]}) ===')\n",
    "bootstrap_mxbai_scifact, pq_mxbai = bootstrap_ndcg(\n",
    "    query_emb, corpus_emb, qrels, doc_id_to_idx, query_ids, METHODS, n_bootstrap=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also run on NFCorpus for comparison\n",
    "dataset2 = 'NFCorpus'\n",
    "ds_key2 = 'nfcorpus'\n",
    "\n",
    "corpus_emb2 = load_emb(model_name, dataset2, 'corpus')\n",
    "query_emb2 = load_emb(model_name, dataset2, 'queries')\n",
    "corpus_data2, queries_data2, qrels2 = data_loader.load_dataset(ds_key2)\n",
    "doc_ids2, _, query_ids2, _ = data_loader.get_texts_for_embedding(corpus_data2, queries_data2)\n",
    "doc_id_to_idx2 = {did: i for i, did in enumerate(doc_ids2)}\n",
    "\n",
    "print(f'\\n=== {model_name} / {dataset2} (full dim={corpus_emb2.shape[1]}) ===')\n",
    "bootstrap_mxbai_nfco, pq_mxbai_nfco = bootstrap_ndcg(\n",
    "    query_emb2, corpus_emb2, qrels2, doc_id_to_idx2, query_ids2, METHODS, n_bootstrap=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bootstrap distributions\n",
    "def plot_bootstrap(bootstrap_results, title, methods_to_compare=None):\n",
    "    if methods_to_compare is None:\n",
    "        methods_to_compare = list(bootstrap_results.keys())\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: distributions\n",
    "    ax = axes[0]\n",
    "    colors = {'float32': '#2ecc71', 'lloyd_max_gauss': '#2c3e50', 'int8_asym': '#1abc9c',\n",
    "              'quaternary_asym': '#8e44ad', 'binary_median_asym': '#c0392b', 'binary_asym': '#e67e22'}\n",
    "    for m in methods_to_compare:\n",
    "        vals = bootstrap_results[m]\n",
    "        ci_lo, ci_hi = np.percentile(vals, [2.5, 97.5])\n",
    "        ax.hist(vals, bins=50, alpha=0.4, color=colors.get(m, 'gray'), label=f'{m}: {np.mean(vals):.4f} [{ci_lo:.4f}, {ci_hi:.4f}]')\n",
    "        ax.axvline(np.mean(vals), color=colors.get(m, 'gray'), linestyle='--', alpha=0.8)\n",
    "    ax.set_xlabel('NDCG@10')\n",
    "    ax.set_ylabel('Bootstrap count')\n",
    "    ax.set_title(f'{title}\\n95% Confidence Intervals')\n",
    "    ax.legend(fontsize=7)\n",
    "    \n",
    "    # Right: pairwise difference (lloyd_max - float32)\n",
    "    ax = axes[1]\n",
    "    if 'lloyd_max_gauss' in bootstrap_results and 'float32' in bootstrap_results:\n",
    "        diff = bootstrap_results['lloyd_max_gauss'] - bootstrap_results['float32']\n",
    "        ci_lo, ci_hi = np.percentile(diff, [2.5, 97.5])\n",
    "        frac_positive = np.mean(diff > 0)\n",
    "        ax.hist(diff, bins=50, alpha=0.6, color='#2c3e50')\n",
    "        ax.axvline(0, color='red', linestyle='-', linewidth=2)\n",
    "        ax.axvline(np.mean(diff), color='#2c3e50', linestyle='--')\n",
    "        ax.set_xlabel('NDCG@10 difference (Lloyd-Max − Float32)')\n",
    "        ax.set_title(f'Lloyd-Max vs Float32\\nP(LM > F32) = {frac_positive:.1%}, 95% CI: [{ci_lo:+.4f}, {ci_hi:+.4f}]')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_bootstrap(bootstrap_mxbai_scifact, 'mxbai / SciFact (1024d)')\n",
    "plot_bootstrap(bootstrap_mxbai_nfco, 'mxbai / NFCorpus (1024d)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 4: Correlation Structure — PCA vs Matryoshka\n",
    "\n",
    "**Question**: Do dimensions have significant correlations that scalar quantization misses?\n",
    "\n",
    "If PCA explains much more variance in k components than the first k Matryoshka dims,\n",
    "there's inter-dimension redundancy that PQ could exploit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Cumulative Variance: PCA vs Matryoshka Dimension Ordering', fontweight='bold')\n",
    "\n",
    "for ax, ds in zip(axes, DATASETS):\n",
    "    for mkey, (mname, full_dim, _) in MODELS.items():\n",
    "        corpus = load_emb(mname, ds, 'corpus')\n",
    "        \n",
    "        # Matryoshka ordering: cumulative variance of first k dims\n",
    "        per_dim_var = np.var(corpus, axis=0)\n",
    "        total_var = per_dim_var.sum()\n",
    "        matryoshka_cumvar = np.cumsum(per_dim_var) / total_var\n",
    "        \n",
    "        # PCA ordering\n",
    "        centered = corpus - corpus.mean(axis=0)\n",
    "        # Use SVD for efficiency (don't need full eigendecomposition)\n",
    "        _, S, _ = np.linalg.svd(centered, full_matrices=False)\n",
    "        pca_var = S**2 / (corpus.shape[0] - 1)\n",
    "        pca_cumvar = np.cumsum(pca_var) / pca_var.sum()\n",
    "        \n",
    "        dims = np.arange(1, full_dim + 1)\n",
    "        ax.plot(dims, matryoshka_cumvar, '-', label=f'{mkey} Matryoshka', alpha=0.8)\n",
    "        ax.plot(dims, pca_cumvar, '--', label=f'{mkey} PCA', alpha=0.6)\n",
    "    \n",
    "    ax.set_xlabel('Number of dimensions')\n",
    "    ax.set_ylabel('Cumulative variance explained')\n",
    "    ax.set_title(ds)\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0.5, 1.01)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the gap at key dims\n",
    "print(f\"\\n{'Model':<10} {'Dataset':<10} {'Dim':>5} {'Matryoshka':>11} {'PCA':>11} {'Gap':>7}\")\n",
    "print('─' * 60)\n",
    "for mkey, (mname, full_dim, _) in MODELS.items():\n",
    "    for ds in DATASETS:\n",
    "        corpus = load_emb(mname, ds, 'corpus')\n",
    "        per_dim_var = np.var(corpus, axis=0)\n",
    "        total_var = per_dim_var.sum()\n",
    "        mat_cumvar = np.cumsum(per_dim_var) / total_var\n",
    "        \n",
    "        centered = corpus - corpus.mean(axis=0)\n",
    "        _, S, _ = np.linalg.svd(centered, full_matrices=False)\n",
    "        pca_var = S**2 / (corpus.shape[0] - 1)\n",
    "        pca_cumvar = np.cumsum(pca_var) / pca_var.sum()\n",
    "        \n",
    "        for dim in [64, 128, 256]:\n",
    "            if dim < full_dim:\n",
    "                m_val = mat_cumvar[dim-1]\n",
    "                p_val = pca_cumvar[dim-1]\n",
    "                print(f\"{mkey:<10} {ds:<10} {dim:>5} {m_val:>10.3%} {p_val:>10.3%} {(p_val-m_val):>6.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-dimension correlation heatmap (first 64 dims)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "fig.suptitle('Inter-Dimension Correlation (first 64 dims)', fontweight='bold')\n",
    "\n",
    "for ax, (mkey, (mname, full_dim, _)) in zip(axes, MODELS.items()):\n",
    "    corpus = load_emb(mname, 'SciFact', 'corpus')\n",
    "    corr = np.corrcoef(corpus[:, :64].T)  # (64, 64)\n",
    "    \n",
    "    # Zero diagonal for visualization\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    \n",
    "    im = ax.imshow(np.abs(corr), cmap='YlOrRd', vmin=0, vmax=0.3)\n",
    "    ax.set_title(f'{mkey}\\nmax |corr| = {np.max(np.abs(corr)):.3f}')\n",
    "    ax.set_xlabel('Dimension')\n",
    "    ax.set_ylabel('Dimension')\n",
    "\n",
    "fig.colorbar(im, ax=axes, label='|Correlation|', shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistic: mean absolute off-diagonal correlation\n",
    "print(f\"\\n{'Model':<10} {'Dataset':<10} {'Mean |corr|':>12} {'Max |corr|':>11} {'Frac |corr|>0.1':>16}\")\n",
    "print('─' * 65)\n",
    "for mkey, (mname, full_dim, _) in MODELS.items():\n",
    "    for ds in DATASETS:\n",
    "        corpus = load_emb(mname, ds, 'corpus')\n",
    "        corr = np.corrcoef(corpus.T)\n",
    "        np.fill_diagonal(corr, 0)\n",
    "        abs_corr = np.abs(corr)\n",
    "        n = corr.shape[0]\n",
    "        n_pairs = n * (n - 1) / 2\n",
    "        upper = abs_corr[np.triu_indices(n, k=1)]\n",
    "        print(f\"{mkey:<10} {ds:<10} {np.mean(upper):>12.4f} {np.max(upper):>11.4f} {np.mean(upper > 0.1):>15.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 5: MSE vs Ranking Quality\n",
    "\n",
    "**Question**: Does lower reconstruction MSE always mean better NDCG?\n",
    "\n",
    "Compute both MSE and NDCG@10 for each method × dim, then plot correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score_mse_and_rank_corr(query_emb, corpus_emb, score_fn):\n",
    "    \"\"\"Compute MSE of scores and Kendall's tau rank correlation vs float32.\"\"\"\n",
    "    # Ground truth scores\n",
    "    gt_scores = query_emb @ corpus_emb.T  # (n_q, n_c)\n",
    "    \n",
    "    # Quantized scores\n",
    "    q_scores = score_fn(query_emb, corpus_emb)\n",
    "    \n",
    "    # Score MSE (averaged over queries)\n",
    "    score_mse = np.mean((gt_scores - q_scores)**2)\n",
    "    \n",
    "    # Rank correlation: for each query, compare top-100 ranking\n",
    "    taus = []\n",
    "    n_queries = min(query_emb.shape[0], 50)  # subsample for speed\n",
    "    for i in range(n_queries):\n",
    "        # Get top-100 by ground truth\n",
    "        gt_top = np.argsort(-gt_scores[i])[:100]\n",
    "        # Rank these docs by quantized scores\n",
    "        gt_ranking = np.argsort(-gt_scores[i, gt_top])\n",
    "        q_ranking = np.argsort(-q_scores[i, gt_top])\n",
    "        tau, _ = stats.kendalltau(gt_ranking, q_ranking)\n",
    "        if not np.isnan(tau):\n",
    "            taus.append(tau)\n",
    "    \n",
    "    mean_tau = np.mean(taus) if taus else 0.0\n",
    "    return score_mse, mean_tau\n",
    "\n",
    "# Run for multiple dims and methods\n",
    "print(f\"{'Model':<10} {'Dataset':<10} {'Dim':>5} {'Method':<25} {'Score MSE':>10} {'Kendall τ':>10}\")\n",
    "print('─' * 80)\n",
    "\n",
    "mse_ndcg_points = []  # (score_mse, kendall_tau, ndcg, method, model, dataset, dim)\n",
    "\n",
    "for mkey, (mname, full_dim, mat_dims) in MODELS.items():\n",
    "    for ds_label, ds_key in [('SciFact', 'scifact'), ('NFCorpus', 'nfcorpus')]:\n",
    "        ds_name = 'SciFact' if ds_key == 'scifact' else 'NFCorpus'\n",
    "        corpus_full = load_emb(mname, ds_name, 'corpus')\n",
    "        query_full = load_emb(mname, ds_name, 'queries')\n",
    "        \n",
    "        for dim in [full_dim, 256] if full_dim > 256 else [full_dim]:\n",
    "            corpus = truncate_normalize(corpus_full, dim)\n",
    "            queries = truncate_normalize(query_full, dim)\n",
    "            \n",
    "            for method_name, score_fn in METHODS.items():\n",
    "                if method_name == 'float32':\n",
    "                    continue  # reference, MSE=0\n",
    "                \n",
    "                mse, tau = compute_score_mse_and_rank_corr(queries, corpus, score_fn)\n",
    "                \n",
    "                # Get NDCG from stored results\n",
    "                model_key = mname.split('/')[-1] if '/' in mname else mname\n",
    "                ndcg = ndcg_lookup.get((model_key, ds_key, method_name, dim, 'none'), None)\n",
    "                \n",
    "                mse_ndcg_points.append((mse, tau, ndcg, method_name, mkey, ds_key, dim))\n",
    "                print(f\"{mkey:<10} {ds_label:<10} {dim:>5} {method_name:<25} {mse:>10.6f} {tau:>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE vs Kendall's tau\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "method_colors = {\n",
    "    'lloyd_max_gauss': '#2c3e50', 'quaternary_asym': '#8e44ad',\n",
    "    'int8_asym': '#1abc9c', 'binary_median_asym': '#c0392b', 'binary_asym': '#e67e22'\n",
    "}\n",
    "method_markers = {\n",
    "    'lloyd_max_gauss': '*', 'quaternary_asym': 'P',\n",
    "    'int8_asym': 'p', 'binary_median_asym': 'H', 'binary_asym': 'v'\n",
    "}\n",
    "\n",
    "# Left: Score MSE vs Kendall's tau\n",
    "ax = axes[0]\n",
    "for mse, tau, ndcg, method, model, ds, dim in mse_ndcg_points:\n",
    "    ax.scatter(mse, tau, c=method_colors.get(method, 'gray'),\n",
    "              marker=method_markers.get(method, 'o'), s=60, alpha=0.7)\n",
    "ax.set_xlabel('Score MSE (lower = better reconstruction)')\n",
    "ax.set_ylabel(\"Kendall's τ (higher = better ranking)\")\n",
    "ax.set_title('Score MSE vs Rank Preservation')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Score MSE vs NDCG (where available)\n",
    "ax = axes[1]\n",
    "for mse, tau, ndcg, method, model, ds, dim in mse_ndcg_points:\n",
    "    if ndcg is not None:\n",
    "        ax.scatter(mse, ndcg, c=method_colors.get(method, 'gray'),\n",
    "                  marker=method_markers.get(method, 'o'), s=60, alpha=0.7)\n",
    "ax.set_xlabel('Score MSE (lower = better reconstruction)')\n",
    "ax.set_ylabel('NDCG@10')\n",
    "ax.set_title('Score MSE vs NDCG@10')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Shared legend\n",
    "from matplotlib.lines import Line2D\n",
    "handles = [Line2D([0], [0], marker=method_markers[m], color=method_colors[m],\n",
    "                  linestyle='None', markersize=8, label=m)\n",
    "          for m in method_colors]\n",
    "axes[0].legend(handles=handles, fontsize=7, loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation between MSE and tau\n",
    "mses = [p[0] for p in mse_ndcg_points]\n",
    "taus = [p[1] for p in mse_ndcg_points]\n",
    "r, p = stats.pearsonr(mses, taus)\n",
    "print(f'\\nCorrelation (MSE vs τ): r = {r:.3f}, p = {p:.4f}')\n",
    "print(f'Interpretation: MSE {\"is\" if abs(r) > 0.7 else \"is NOT\"} a reliable proxy for ranking quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 6: Calibration-Free 2-bit Quantization\n",
    "\n",
    "**Idea**: Use fixed boundaries that don't depend on calibration data.\n",
    "For L2-normalized embeddings, each dim is in [-1, 1] with mean ≈ 0.\n",
    "\n",
    "We test several fixed boundary choices vs Lloyd-Max (which needs calibration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_fixed_2bit(q, c, boundaries, levels):\n",
    "    \"\"\"2-bit quantization with fixed (calibration-free) boundaries and levels.\"\"\"\n",
    "    codes = np.digitize(c, boundaries).astype(np.uint8)\n",
    "    recon = levels[codes]\n",
    "    return q @ recon.T\n",
    "\n",
    "# Different fixed boundary strategies\n",
    "def make_universal_quantizer(dim):\n",
    "    \"\"\"Boundaries scaled by expected std of L2-normalized embeddings.\"\"\"\n",
    "    # For unit vectors in R^d, each coord has std ≈ 1/sqrt(d)\n",
    "    sigma_est = 1.0 / np.sqrt(dim)\n",
    "    bounds = np.array([-0.9816, 0.0, 0.9816]) * sigma_est\n",
    "    levels = np.array([-1.5104, -0.4528, 0.4528, 1.5104], dtype=np.float32) * sigma_est\n",
    "    return bounds, levels\n",
    "\n",
    "def make_uniform_quantizer(dim):\n",
    "    \"\"\"Uniform spacing over plausible range.\"\"\"\n",
    "    r = 3.0 / np.sqrt(dim)  # ±3σ\n",
    "    bounds = np.array([-r/2, 0, r/2])\n",
    "    levels = np.array([-3*r/4, -r/4, r/4, 3*r/4], dtype=np.float32)\n",
    "    return bounds, levels\n",
    "\n",
    "def make_sign_only_quantizer():\n",
    "    \"\"\"Just sign + magnitude split at a fixed threshold. Like 2-bit sign-magnitude.\"\"\"\n",
    "    bounds = np.array([-0.03, 0.0, 0.03])  # narrow dead zone around 0\n",
    "    levels = np.array([-0.06, -0.015, 0.015, 0.06], dtype=np.float32)\n",
    "    return bounds, levels\n",
    "\n",
    "# Compare on all model/dataset combos\n",
    "print(f\"{'Model':<10} {'Dataset':<10} {'Dim':>5} {'Float32':>8} {'Lloyd-Max':>10} {'Universal':>10} {'Uniform':>10}\")\n",
    "print('─' * 75)\n",
    "\n",
    "calib_free_results = []\n",
    "\n",
    "for mkey, (mname, full_dim, mat_dims) in MODELS.items():\n",
    "    for ds_name in DATASETS:\n",
    "        ds_key = 'scifact' if ds_name == 'SciFact' else 'nfcorpus'\n",
    "        corpus_full = load_emb(mname, ds_name, 'corpus')\n",
    "        query_full = load_emb(mname, ds_name, 'queries')\n",
    "        \n",
    "        corpus_data_ds, queries_data_ds, qrels_ds = data_loader.load_dataset(ds_key)\n",
    "        doc_ids_ds, _, query_ids_ds, _ = data_loader.get_texts_for_embedding(corpus_data_ds, queries_data_ds)\n",
    "        d2i = {did: i for i, did in enumerate(doc_ids_ds)}\n",
    "        \n",
    "        for dim in mat_dims:\n",
    "            corpus = truncate_normalize(corpus_full, dim)\n",
    "            queries = truncate_normalize(query_full, dim)\n",
    "            \n",
    "            # Float32 baseline\n",
    "            s_f32 = get_scores_float32(queries, corpus)\n",
    "            idx_f32 = search_topk(s_f32, 100)\n",
    "            m_f32 = RetrievalMetrics.compute_all_metrics(idx_f32, qrels_ds, d2i, query_ids_ds, [10])\n",
    "            \n",
    "            # Lloyd-Max (calibrated)\n",
    "            s_lm = get_scores_lloyd_max(queries, corpus)\n",
    "            idx_lm = search_topk(s_lm, 100)\n",
    "            m_lm = RetrievalMetrics.compute_all_metrics(idx_lm, qrels_ds, d2i, query_ids_ds, [10])\n",
    "            \n",
    "            # Universal (calibration-free)\n",
    "            ub, ul = make_universal_quantizer(dim)\n",
    "            s_uni = get_scores_fixed_2bit(queries, corpus, ub, ul)\n",
    "            idx_uni = search_topk(s_uni, 100)\n",
    "            m_uni = RetrievalMetrics.compute_all_metrics(idx_uni, qrels_ds, d2i, query_ids_ds, [10])\n",
    "            \n",
    "            # Uniform spacing\n",
    "            ub2, ul2 = make_uniform_quantizer(dim)\n",
    "            s_uf = get_scores_fixed_2bit(queries, corpus, ub2, ul2)\n",
    "            idx_uf = search_topk(s_uf, 100)\n",
    "            m_uf = RetrievalMetrics.compute_all_metrics(idx_uf, qrels_ds, d2i, query_ids_ds, [10])\n",
    "            \n",
    "            row = (mkey, ds_name, dim,\n",
    "                   m_f32['ndcg@10'], m_lm['ndcg@10'], m_uni['ndcg@10'], m_uf['ndcg@10'])\n",
    "            calib_free_results.append(row)\n",
    "            print(f\"{mkey:<10} {ds_name:<10} {dim:>5} {row[3]:>8.4f} {row[4]:>10.4f} {row[5]:>10.4f} {row[6]:>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: How much does calibration-free lose vs Lloyd-Max?\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Calibration-Free 2-bit vs Lloyd-Max (Calibrated)', fontweight='bold')\n",
    "\n",
    "for ax, ds in zip(axes, DATASETS):\n",
    "    for mkey, (mname, full_dim, mat_dims) in MODELS.items():\n",
    "        if len(mat_dims) <= 1:\n",
    "            continue\n",
    "        rows = [(d, f32, lm, uni, uf) for mk, dsn, d, f32, lm, uni, uf in calib_free_results\n",
    "                if mk == mkey and dsn == ds]\n",
    "        if not rows:\n",
    "            continue\n",
    "        dims = [r[0] for r in rows]\n",
    "        f32s = [r[1] for r in rows]\n",
    "        lms = [r[2] for r in rows]\n",
    "        unis = [r[3] for r in rows]\n",
    "        ufs = [r[4] for r in rows]\n",
    "        \n",
    "        ax.plot(dims, f32s, 'o-', color='#2ecc71', label=f'{mkey} float32', alpha=0.5)\n",
    "        ax.plot(dims, lms, 's-', color='#2c3e50', label=f'{mkey} Lloyd-Max')\n",
    "        ax.plot(dims, unis, '^--', color='#e74c3c', label=f'{mkey} Universal (calib-free)')\n",
    "        ax.plot(dims, ufs, 'v:', color='#3498db', label=f'{mkey} Uniform (calib-free)')\n",
    "    \n",
    "    ax.set_xlabel('Dimension')\n",
    "    ax.set_ylabel('NDCG@10')\n",
    "    ax.set_title(ds)\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary: how much does calibration buy you?\n",
    "print('\\nCalibration benefit (Lloyd-Max NDCG − Universal NDCG):')\n",
    "print(f\"{'Model':<10} {'Dataset':<10} {'Dim':>5} {'Lloyd-Max':>10} {'Universal':>10} {'Gap':>7}\")\n",
    "print('─' * 55)\n",
    "for mkey, ds, dim, f32, lm, uni, uf in calib_free_results:\n",
    "    gap = lm - uni\n",
    "    print(f\"{mkey:<10} {ds:<10} {dim:>5} {lm:>10.4f} {uni:>10.4f} {gap:>+7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Conclusions\n",
    "\n",
    "Collect the key findings from all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('SUMMARY OF FINDINGS')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\n1. DISTRIBUTION ANALYSIS')\n",
    "print('─' * 40)\n",
    "for mkey, (mname, full_dim, _) in MODELS.items():\n",
    "    for ds in DATASETS:\n",
    "        r = all_results.get((mkey, ds, full_dim))\n",
    "        if r:\n",
    "            kurt = r['kurtosis_mean']\n",
    "            deviation = abs(kurt - 3.0)\n",
    "            assessment = 'Near-Gaussian' if deviation < 0.5 else ('Heavy-tailed' if kurt > 3 else 'Light-tailed')\n",
    "            print(f'  {mkey}/{ds}: kurtosis={kurt:.2f} ({assessment}), '\n",
    "                  f'|median| RMS={r[\"median_offset_rms\"]:.4f}, '\n",
    "                  f'Shapiro reject={r[\"shapiro_reject_frac\"]:.0%}')\n",
    "\n",
    "print('\\n2. BOOTSTRAP CONFIDENCE INTERVALS')\n",
    "print('─' * 40)\n",
    "for name, bs in [('mxbai/SciFact', bootstrap_mxbai_scifact), ('mxbai/NFCorpus', bootstrap_mxbai_nfco)]:\n",
    "    diff = bs['lloyd_max_gauss'] - bs['float32']\n",
    "    ci_lo, ci_hi = np.percentile(diff, [2.5, 97.5])\n",
    "    sig = 'SIGNIFICANT' if (ci_lo > 0 or ci_hi < 0) else 'NOT significant'\n",
    "    print(f'  {name}: Lloyd-Max − Float32 = {np.mean(diff):+.4f} '\n",
    "          f'[{ci_lo:+.4f}, {ci_hi:+.4f}] → {sig}')\n",
    "\n",
    "print('\\n3. CORRELATION STRUCTURE')\n",
    "print('─' * 40)\n",
    "print('  (See PCA vs Matryoshka and correlation heatmap plots above)')\n",
    "\n",
    "print('\\n4. MSE vs RANKING')\n",
    "print('─' * 40)\n",
    "mses_all = [p[0] for p in mse_ndcg_points]\n",
    "taus_all = [p[1] for p in mse_ndcg_points]\n",
    "r_val, _ = stats.pearsonr(mses_all, taus_all)\n",
    "print(f'  Score MSE vs Kendall τ correlation: r = {r_val:.3f}')\n",
    "print(f'  → MSE {\"IS\" if abs(r_val) > 0.7 else \"is NOT\"} a reliable proxy for ranking quality')\n",
    "\n",
    "print('\\n5. CALIBRATION-FREE 2-BIT')\n",
    "print('─' * 40)\n",
    "gaps = [lm - uni for _, _, _, _, lm, uni, _ in calib_free_results]\n",
    "print(f'  Mean gap (Lloyd-Max − Universal): {np.mean(gaps):+.4f}')\n",
    "print(f'  Max gap: {np.max(gaps):+.4f}')\n",
    "print(f'  → Calibration {\"matters significantly\" if np.mean(gaps) > 0.01 else \"provides marginal benefit\"}')\n",
    "\n",
    "print('\\n' + '=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
